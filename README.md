# Scraping_for_-Tahrirchi-
Especially scraping for the "Tahrirchi"

I chose kun.uz for information because it is in Uzbek. my program always works, because when news comes out, it immediately saves the news as a data structure to the sqlite repository.

I did not separate the words, that would be a mistake, because there is no point in repeating the same information,
I implemented this in another function that creates an array of "words" and removes the duplicates and gives us the cvs format type "python get_data_to_csv.py" in terminal to run this function, 
Please note that if you use this code our sqlite repository will be cleared i.e. after the data is passed to cvs, the old one will be removed.

Yes, it's not a good way to collect data, but I've done it in my time, I think the best way to collect data is a NoSql database.
